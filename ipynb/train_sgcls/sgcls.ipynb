{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "codebase = '/home/ce/hikersgg/'\n",
    "sys.path.append(\"/home/ce/hikersgg/\")\n",
    "# sys.path.append('../../../')\n",
    "# sys.path.append('../../../apex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'hikersgg_sgcls_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time as time_time\n",
    "import numpy as np\n",
    "# from torch import optim\n",
    "from apex import amp\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "write = tqdm.write\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from config import ModelConfig, BOX_SCALE, IM_SCALE\n",
    "from torch.nn import functional as F\n",
    "from lib.pytorch_misc import optimistic_restore, de_chunkize, clip_grad_norm\n",
    "from lib.evaluation.sg_eval import BasicSceneGraphEvaluator, calculate_mR_from_evaluator_list, eval_entry\n",
    "from lib.pytorch_misc import print_para\n",
    "from dataloaders.visual_genome import VGDataLoader, VG\n",
    "\n",
    "from lib.my_model_24 import KERN\n",
    "\n",
    "# sg val\n",
    "# import numpy\n",
    "# import pyximport\n",
    "# pyximport.install(setup_args={\"script_args\":[\"--compiler=mingw32\"],\n",
    "#                               \"include_dirs\":numpy.get_include()},\n",
    "#                   reload_support=True)\n",
    "# then delete \"script_args\":[\"--compiler=mingw32\"],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = ModelConfig(f'''\n",
    "-m sgcls -p 2500 -clip 5\n",
    "-tb_log_dir summaries/kern_sgcls/{exp_name}\n",
    "-save_dir checkpoints/kern_sgcls/{exp_name}\n",
    "-ckpt checkpoints/kern_predcls/hikersgg_predcls_train/vgrel-10.tar\n",
    "-val_size 5000\n",
    "-adam\n",
    "-b 3\n",
    "-ngpu 1\n",
    "-lr 1e-5\n",
    "''')\n",
    "\n",
    "# Also load the corresponding confusion matrix\n",
    "conf_matrix = np.load('/home/ce/data/vg/conf/conf_mat_updated_8.npy') # Remember to change to the path of the confusion matrix\n",
    "np.save('/home/ce/data/vg/conf_mat_updated.npy', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified\n",
    "conf.MODEL.CONF_MAT_FREQ_TRAIN = '/home/ce/data/vg/conf_mat_freq_train.npy'\n",
    "conf.MODEL.LRGA.USE_LRGA = False\n",
    "conf.MODEL.USE_ONTOLOGICAL_ADJUSTMENT = False\n",
    "conf.MODEL.NORMALIZE_EOA = False\n",
    "conf.num_workers = 9\n",
    "# conf.MODEL.LRGA.K = 50\n",
    "# conf.MODEL.LRGA.DROPOUT = 0.5\n",
    "# conf.MODEL.GN.NUM_GROUPS = 1024//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluating the confusion matrix\n",
    "train_full, val, test = VG.splits(num_val_im=conf.val_size, filter_duplicate_rels=True,\n",
    "                            use_proposals=conf.use_proposals,\n",
    "                            filter_non_overlap=conf.mode == 'sgdet', with_clean_classifier=False, get_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_full_loader = VGDataLoader.splits(train_full, train_full, mode='rel',\n",
    "                                               batch_size=conf.batch_size,\n",
    "                                               num_workers=conf.num_workers,\n",
    "                                               num_gpus=conf.num_gpus,\n",
    "                                               pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = VG.splits(num_val_im=conf.val_size, filter_duplicate_rels=True,\n",
    "                            use_proposals=conf.use_proposals,\n",
    "                            filter_non_overlap=conf.mode == 'sgdet', with_clean_classifier=True, get_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_predicates = train.ind_to_predicates # ind_to_predicates[0] means no relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = VGDataLoader.splits(train, val, mode='rel',\n",
    "                                               batch_size=conf.batch_size,\n",
    "                                               num_workers=conf.num_workers,\n",
    "                                               num_gpus=conf.num_gpus,\n",
    "                                               pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = KERN(classes=train.ind_to_classes, rel_classes=train.ind_to_predicates,\n",
    "                num_gpus=conf.num_gpus, mode=conf.mode, require_overlap_det=True,\n",
    "                use_resnet=conf.use_resnet, use_proposals=conf.use_proposals, pooling_dim=conf.pooling_dim,\n",
    "                ggnn_rel_time_step_num=3, ggnn_rel_hidden_dim=1024, ggnn_rel_output_dim=None,\n",
    "                graph_path=os.path.join(codebase, 'graphs/005/all_edges.pkl'),\n",
    "                emb_path=os.path.join(codebase, 'graphs/001/emb_mtx.pkl'),\n",
    "                rel_counts_path=os.path.join(codebase, 'graphs/001/pred_counts.pkl'),\n",
    "                use_knowledge=True, use_embedding=True, refine_obj_cls=True,\n",
    "                class_volume=1.0, with_clean_classifier=True, with_transfer=True, sa=True, config=conf,\n",
    "                ) # Set refine_obj_cls=True for SGCls task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the detector\n",
    "for n, param in detector.detector.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex.optimizers import FusedAdam, FusedSGD\n",
    "from torch import optim\n",
    "\n",
    "def get_optim(lr):\n",
    "    # Lower the learning rate on the VGG fully connected layers by 1/10th. It's a hack, but it helps\n",
    "    # stabilize the models.\n",
    "    fc_params = [p for n,p in detector.named_parameters() if (n.startswith('roi_fmap') or 'clean' in n) and p.requires_grad]\n",
    "    non_fc_params = [p for n,p in detector.named_parameters() if not (n.startswith('roi_fmap') or 'clean' in n) and p.requires_grad]\n",
    "    params = [{'params': fc_params, 'lr': lr / 10.0}, {'params': non_fc_params}]\n",
    "    # params = [p for n,p in detector.named_parameters() if p.requires_grad]\n",
    "\n",
    "    if conf.adam:\n",
    "        optimizer = FusedAdam(params, weight_decay=conf.adamwd, lr=lr, eps=1e-3)\n",
    "        # optimizer = optim.Adam(params, weight_decay=conf.adamwd, lr=lr, eps=1e-3)\n",
    "    else:\n",
    "        optimizer = FusedSGD(params, weight_decay=conf.l2, lr=lr, momentum=0.9)\n",
    "        # optimizer = optim.SGD(params, weight_decay=conf.l2, lr=lr, momentum=0.9)\n",
    "\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.1,\n",
    "    #                               verbose=True, threshold=0.0001, threshold_mode='abs', cooldown=1)\n",
    "    return optimizer #, scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(conf.ckpt)\n",
    "optimistic_restore(detector, ckpt['state_dict'], skip_clean=False)\n",
    "detector.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time as time_time\n",
    "def train_epoch(epoch_num):\n",
    "    detector.train()\n",
    "    tr = []\n",
    "    start = time_time()\n",
    "    prog_bar = tqdm(enumerate(train_loader), total=int(len(train)/train_loader.batch_size))\n",
    "    for b, batch in prog_bar:\n",
    "        # print(train_batch(batch, verbose=b % (conf.print_interval*10) == 0))\n",
    "        result, loss_dict = train_batch(batch, verbose=b % (conf.print_interval*10) == 0)\n",
    "        tr.append(loss_dict)\n",
    "        '''\n",
    "        if b % 100 == 0:\n",
    "            print(loss_pd)\n",
    "            gt = result.rel_labels[:,3].data.cpu().numpy()\n",
    "            out = result.rel_dists.data.cpu().numpy()\n",
    "            ind = np.where(gt)[0]\n",
    "            print(gt[ind])\n",
    "            print(np.argmax(out[ind], 1))\n",
    "            print(np.argmax(out[ind, 1:], 1) + 1)\n",
    "        '''\n",
    "\n",
    "        if b % conf.print_interval == 0 and b >= conf.print_interval:\n",
    "#             mn = pd.DataFrame([pd.Series(dicty) for dicty in tr[-conf.print_interval:]]).mean(1)\n",
    "            mn = pd.DataFrame(tr[-conf.print_interval:]).mean(axis=0)\n",
    "            time_per_batch = (time_time() - start) / conf.print_interval\n",
    "            write(\"\\ne{:2d}b{:5d}/{:5d} {:.3f}s/batch, {:.1f}m/epoch\".format(\n",
    "                epoch_num, b, len(train_loader), time_per_batch, len(train_loader) * time_per_batch / 60))\n",
    "            write(mn.to_string())\n",
    "            write('-----------')\n",
    "            start = time_time()\n",
    "    return pd.DataFrame(tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "def train_batch(b, verbose=False):\n",
    "    \"\"\"\n",
    "    :param b: contains:\n",
    "          :param imgs: the image, [batch_size, 3, IM_SIZE, IM_SIZE]\n",
    "          :param all_anchors: [num_anchors, 4] the boxes of all anchors that we'll be using\n",
    "          :param all_anchor_inds: [num_anchors, 2] array of the indices into the concatenated\n",
    "                                  RPN feature vector that give us all_anchors,\n",
    "                                  each one (img_ind, fpn_idx)\n",
    "          :param im_sizes: a [batch_size, 4] numpy array of (h, w, scale, num_good_anchors) for each image.\n",
    "\n",
    "          :param num_anchors_per_img: int, number of anchors in total over the feature pyramid per img\n",
    "\n",
    "          Training parameters:\n",
    "          :param train_anchor_inds: a [num_train, 5] array of indices for the anchors that will\n",
    "                                    be used to compute the training loss (img_ind, fpn_idx)\n",
    "          :param gt_boxes: [num_gt, 4] GT boxes over the batch.\n",
    "          :param gt_classes: [num_gt, 2] gt boxes where each one is (img_id, class)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    with autocast():\n",
    "        result = detector[b]\n",
    "        loss_class = detector.obj_loss(result)\n",
    "        loss_rel = detector.rel_loss(result)\n",
    "        loss = loss_class + loss_rel\n",
    "    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        scaled_loss.backward()\n",
    "    clip_grad_norm(\n",
    "        [(n, p) for n, p in detector.named_parameters() if p.grad is not None],\n",
    "        max_norm=conf.clip, verbose=verbose, clip=True)\n",
    "    optimizer.step()\n",
    "    return result, {\n",
    "          'loss_class': float(loss_class),\n",
    "          'loss_rel': float(loss_rel),\n",
    "          'loss_total': float(loss),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad as torch_no_grad\n",
    "from tqdm import tqdm\n",
    "\n",
    "def val_epoch():\n",
    "    detector.eval()\n",
    "    evaluator_list = [] # for calculating recall of each relationship except no relationship\n",
    "    evaluator_multiple_preds_list = []\n",
    "    for index, name in enumerate(ind_to_predicates):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        evaluator_list.append((index, name, BasicSceneGraphEvaluator.all_modes()))\n",
    "        evaluator_multiple_preds_list.append((index, name, BasicSceneGraphEvaluator.all_modes(multiple_preds=True)))\n",
    "    evaluator = BasicSceneGraphEvaluator.all_modes() # for calculating recall\n",
    "    evaluator_multiple_preds = BasicSceneGraphEvaluator.all_modes(multiple_preds=True)\n",
    "\n",
    "    prog_bar = tqdm(enumerate(val_loader), total=int(len(val)/val_loader.batch_size))\n",
    "\n",
    "    with torch_no_grad():\n",
    "        for val_b, batch in prog_bar:\n",
    "            val_batch(conf.num_gpus * val_b, batch, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list)\n",
    "\n",
    "    recall = evaluator[conf.mode].print_stats()\n",
    "    recall_mp = evaluator_multiple_preds[conf.mode].print_stats()\n",
    "\n",
    "    mean_recall = calculate_mR_from_evaluator_list(evaluator_list, conf.mode)\n",
    "    mean_recall_mp = calculate_mR_from_evaluator_list(evaluator_multiple_preds_list, conf.mode, multiple_preds=True)\n",
    "\n",
    "    detector.train()\n",
    "    return recall, recall_mp, mean_recall, mean_recall_mp\n",
    "\n",
    "def val_batch(batch_num, b, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list):\n",
    "    with autocast():\n",
    "        det_res = detector[b]\n",
    "    if conf.num_gpus == 1:\n",
    "        det_res = [det_res]\n",
    "\n",
    "    for i, (boxes_i, objs_i, obj_scores_i, rels_i, pred_scores_i) in enumerate(det_res):\n",
    "        gt_entry = {\n",
    "            'gt_classes': val.gt_classes[batch_num + i].copy(),\n",
    "            'gt_relations': val.relationships[batch_num + i].copy(),\n",
    "            'gt_boxes': val.gt_boxes[batch_num + i].copy(),\n",
    "        }\n",
    "        assert np.all(objs_i[rels_i[:, 0]] > 0) and np.all(objs_i[rels_i[:, 1]] > 0)\n",
    "\n",
    "        pred_entry = {\n",
    "            'pred_boxes': boxes_i * BOX_SCALE/IM_SCALE,\n",
    "            'pred_classes': objs_i,\n",
    "            'pred_rel_inds': rels_i,\n",
    "            'obj_scores': obj_scores_i,\n",
    "            'rel_scores': pred_scores_i,  # hack for now.\n",
    "        }\n",
    "\n",
    "        eval_entry(conf.mode, gt_entry, pred_entry, evaluator, evaluator_multiple_preds,\n",
    "                   evaluator_list, evaluator_multiple_preds_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "optimizer = get_optim(conf.lr * conf.num_gpus * conf.batch_size)\n",
    "detector, optimizer = amp.initialize(detector, optimizer, opt_level=\"O0\")\n",
    "\n",
    "start_epoch = 0\n",
    "end_epoch = 20\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "\n",
    "    write(f'epoch = {epoch}')\n",
    "    if epoch != 0 and epoch % 10 == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] /= 10\n",
    "\n",
    "    rez = train_epoch(epoch)\n",
    "    losses_mean_epoch = rez.mean(axis=0)\n",
    "    losses_mean_epoch_class = losses_mean_epoch['loss_class']\n",
    "    losses_mean_epoch_rel = losses_mean_epoch['loss_rel']\n",
    "    losses_mean_epoch_total = losses_mean_epoch['loss_total']\n",
    "    write(\"overall{:2d}: ({:.3f})\\n{}\".format(epoch, losses_mean_epoch_total, losses_mean_epoch))\n",
    "\n",
    "    if conf.save_dir is not None:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': detector.state_dict(), #{k:v for k,v in detector.state_dict().items() if not k.startswith('detector.')},\n",
    "            # 'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(conf.save_dir, '{}-{}.tar'.format('vgrel', epoch)))\n",
    "        print(os.path.join(conf.save_dir, '{}-{}.tar'.format('vgrel', epoch)))\n",
    "\n",
    "    recall, recall_mp, mean_recall, mean_recall_mp = val_epoch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
