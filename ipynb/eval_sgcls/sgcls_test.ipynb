{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 309\n",
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "codebase = '/home/ce/hikersgg/'\n",
    "sys.path.append(\"/home/ce/hikersgg/\")\n",
    "# sys.path.append('../../../')\n",
    "# sys.path.append('../../../apex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'hikersgg_sgcls_test' # Change to the experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time as time_time\n",
    "import numpy as np\n",
    "# from torch import optim\n",
    "from apex import amp\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "write = tqdm.write\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from config import ModelConfig, BOX_SCALE, IM_SCALE\n",
    "from torch.nn import functional as F\n",
    "from lib.pytorch_misc import optimistic_restore, de_chunkize, clip_grad_norm\n",
    "from lib.evaluation.sg_eval import BasicSceneGraphEvaluator, calculate_mR_from_evaluator_list, eval_entry\n",
    "from lib.pytorch_misc import print_para\n",
    "from dataloaders.visual_genome import VGDataLoader, VG\n",
    "\n",
    "from lib.my_model_24 import KERN\n",
    "\n",
    "# sg val\n",
    "# import numpy\n",
    "# import pyximport\n",
    "# pyximport.install(setup_args={\"script_args\":[\"--compiler=mingw32\"],\n",
    "#                               \"include_dirs\":numpy.get_include()},\n",
    "#                   reload_support=True)\n",
    "# then delete \"script_args\":[\"--compiler=mingw32\"],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = ModelConfig(f'''\n",
    "-m sgcls -p 1000 -clip 5\n",
    "-ckpt checkpoints/kern_sgcls/hikersgg_sgcls_train/vgrel-0.tar\n",
    "-test\n",
    "-adam\n",
    "-b 1\n",
    "-ngpu 1\n",
    "-lr 1e-5\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified\n",
    "conf.MODEL.CONF_MAT_FREQ_TRAIN = '/home/ce/data/vg/conf_mat_freq_train.npy'\n",
    "conf.MODEL.LRGA.USE_LRGA = False\n",
    "conf.MODEL.USE_ONTOLOGICAL_ADJUSTMENT = False\n",
    "conf.MODEL.NORMALIZE_EOA = False\n",
    "conf.num_workers = 9\n",
    "# conf.MODEL.LRGA.K = 50\n",
    "# conf.MODEL.LRGA.DROPOUT = 0.5\n",
    "# conf.MODEL.GN.NUM_GROUPS = 1024//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = VG.splits(num_val_im=conf.val_size, filter_duplicate_rels=True,\n",
    "                          use_proposals=conf.use_proposals,\n",
    "                          filter_non_overlap=conf.mode == 'sgdet', with_clean_classifier=True,\n",
    "                          get_state=False, test_n=conf.test_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_predicates = train.ind_to_predicates # ind_to_predicates[0] means no relationship\n",
    "if conf.test:\n",
    "    val = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = VGDataLoader.splits(train, val, mode='rel',\n",
    "                                               batch_size=conf.batch_size,\n",
    "                                               num_workers=conf.num_workers,\n",
    "                                               num_gpus=conf.num_gpus,\n",
    "                                               pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = KERN(classes=train.ind_to_classes, rel_classes=train.ind_to_predicates,\n",
    "                num_gpus=conf.num_gpus, mode=conf.mode, require_overlap_det=True,\n",
    "                use_resnet=conf.use_resnet, use_proposals=conf.use_proposals, pooling_dim=conf.pooling_dim,\n",
    "                ggnn_rel_time_step_num=3, ggnn_rel_hidden_dim=1024, ggnn_rel_output_dim=None,\n",
    "                graph_path=os.path.join(codebase, 'graphs/005/all_edges.pkl'),\n",
    "                emb_path=os.path.join(codebase, 'graphs/001/emb_mtx.pkl'),\n",
    "                rel_counts_path=os.path.join(codebase, 'graphs/001/pred_counts.pkl'),\n",
    "                use_knowledge=True, use_embedding=True, refine_obj_cls=True,\n",
    "                class_volume=1.0, with_clean_classifier=True, with_transfer=True, sa=True, config=conf,\n",
    "                ) # Set refine_obj_cls=True for SGCls task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(conf.ckpt)\n",
    "optimistic_restore(detector, ckpt['state_dict'], skip_clean=False)\n",
    "detector.cuda();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad as torch_no_grad\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def val_epoch():\n",
    "    detector.eval()\n",
    "    evaluator_list = [] # for calculating recall of each relationship except no relationship\n",
    "    evaluator_multiple_preds_list = []\n",
    "    for index, name in enumerate(ind_to_predicates):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        evaluator_list.append((index, name, BasicSceneGraphEvaluator.all_modes()))\n",
    "        evaluator_multiple_preds_list.append((index, name, BasicSceneGraphEvaluator.all_modes(multiple_preds=True)))\n",
    "    evaluator = BasicSceneGraphEvaluator.all_modes() # for calculating recall\n",
    "    evaluator_multiple_preds = BasicSceneGraphEvaluator.all_modes(multiple_preds=True)\n",
    "\n",
    "    prog_bar = tqdm(enumerate(val_loader), total=int(len(val)/val_loader.batch_size))\n",
    "\n",
    "    with torch_no_grad():\n",
    "        for val_b, batch in prog_bar:\n",
    "            val_batch(conf.num_gpus * val_b, batch, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list)\n",
    "\n",
    "    recall = evaluator[conf.mode].print_stats()\n",
    "    recall_mp = evaluator_multiple_preds[conf.mode].print_stats()\n",
    "\n",
    "    mean_recall = calculate_mR_from_evaluator_list(evaluator_list, conf.mode)\n",
    "    mean_recall_mp = calculate_mR_from_evaluator_list(evaluator_multiple_preds_list, conf.mode, multiple_preds=True)\n",
    "\n",
    "    detector.train()\n",
    "    return recall, recall_mp, mean_recall, mean_recall_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "\n",
    "def val_batch(batch_num, b, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list):\n",
    "    with autocast():\n",
    "        det_res = detector[b]\n",
    "    if conf.num_gpus == 1:\n",
    "        det_res = [det_res]\n",
    "\n",
    "    for i, (boxes_i, objs_i, obj_scores_i, rels_i, pred_scores_i) in enumerate(det_res):\n",
    "        gt_entry = {\n",
    "            'gt_classes': val.gt_classes[batch_num + i].copy(),\n",
    "            'gt_relations': val.relationships[batch_num + i].copy(),\n",
    "            'gt_boxes': val.gt_boxes[batch_num + i].copy(),\n",
    "        }\n",
    "        assert np.all(objs_i[rels_i[:, 0]] > 0) and np.all(objs_i[rels_i[:, 1]] > 0)\n",
    "\n",
    "        pred_entry = {\n",
    "            'pred_boxes': boxes_i * BOX_SCALE/IM_SCALE,\n",
    "            'pred_classes': objs_i,\n",
    "            'pred_rel_inds': rels_i,\n",
    "            'obj_scores': obj_scores_i,\n",
    "            'rel_scores': pred_scores_i,  # hack for now.\n",
    "        }\n",
    "\n",
    "        eval_entry(conf.mode, gt_entry, pred_entry, evaluator, evaluator_multiple_preds, \n",
    "                   evaluator_list, evaluator_multiple_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "detector.eval()\n",
    "recall, recall_mp, mean_recall, mean_recall_mp = val_epoch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
